{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "diversity.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LleilaA13/Thesis-MUL/blob/main/notebooks/diversity.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ccq4t89VkPUr"
      },
      "source": [
        "##### Licensed under the Apache License, Version 2.0 (the \"License\");"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iiydswCykMPJ"
      },
      "source": [
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WFxVJ9GEkZP7"
      },
      "source": [
        "# The Diversity Objective\n",
        "\n",
        "This notebook demonstrates the diversity objective, which is used to generate multiple different visualizations from a single neuron or channel."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uUMzEXJJkx3H"
      },
      "source": [
        "## Install, Import, Load Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CaCvxcW3kYnd",
        "outputId": "27878187-df6f-4e82-f40b-fec7be687a7c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install --quiet git+https://github.com/greentfrapp/lucent.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m82.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m61.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m45.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[32m565.7/664.8 MB\u001b[0m \u001b[31m143.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MnjhvDrFkz6Y"
      },
      "source": [
        "import torch\n",
        "\n",
        "from lucent.optvis import render, param, transform, objectives\n",
        "from lucent.modelzoo import inceptionv1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9MzZDxhGk3c1"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = inceptionv1(pretrained=True)\n",
        "_ = model.to(device).eval()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Ut62Mcwk8GU"
      },
      "source": [
        "## An Example\n",
        "\n",
        "With the diversity objective, we have to submit a batch of images for optimization. The diversity objective then tries to maximize the difference in feature representations between the images in the batch.\n",
        "\n",
        "Specifically, the objective penalizes cosine similarity between the feature representations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ac83ed7bk9yC"
      },
      "source": [
        "batch_param_f = lambda: param.image(128, batch=4)\n",
        "\n",
        "obj = objectives.channel(\"mixed5a\", 9) - 1e2 * objectives.diversity(\"mixed5a\")\n",
        "\n",
        "_ = render.render_vis(model, obj, batch_param_f, show_inline=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D5ph2YLbm_wy"
      },
      "source": [
        "## More Examples\n",
        "\n",
        "More examples reproducing results from the Distill article [Feature Visualization](https://distill.pub/2017/feature-visualization/)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WO2rOb0ynKKc"
      },
      "source": [
        "# Different curvy facets\n",
        "\n",
        "obj = objectives.channel(\"mixed4a\", 97) - 1e3 * objectives.diversity(\"mixed4a\") # here we use a higher weight on the diversity term\n",
        "\n",
        "_ = render.render_vis(model, obj, batch_param_f, show_inline=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IHjIBu6SnK69"
      },
      "source": [
        "# Different shapes with the same fur texture\n",
        "\n",
        "obj = objectives.channel(\"mixed4a\", 143) - 1e2 * objectives.diversity(\"mixed4a\")\n",
        "\n",
        "_ = render.render_vis(model, obj, batch_param_f, show_inline=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZmmS4duOoU65"
      },
      "source": [
        "# Cars and Cats\n",
        "\n",
        "obj = objectives.channel(\"mixed4e\", 55) - 1e2 * objectives.diversity(\"mixed4e\")\n",
        "\n",
        "_ = render.render_vis(model, obj, batch_param_f, show_inline=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fkPJUbR7qCW2"
      },
      "source": [
        "## Try it out!\n",
        "\n",
        "Select your favorite channel or neuron or just pick a random one! Try adjusting the weight on the diversity term to see how that makes a difference!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uSIaYrRdofil"
      },
      "source": [
        "# Flowers and err... other stuff?\n",
        "\n",
        "batch_param_f = lambda: param.image(128, batch=4, decorrelate=False) # disable channel decorrelation for more trippy images\n",
        "\n",
        "obj = objectives.channel(\"mixed4d_3x3_bottleneck_pre_relu_conv\", 139) - 1e3 * objectives.diversity(\"mixed4d_3x3_bottleneck_pre_relu_conv\")\n",
        "\n",
        "_ = render.render_vis(model, obj, batch_param_f, show_inline=True)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}