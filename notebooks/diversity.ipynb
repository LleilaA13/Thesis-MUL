{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LleilaA13/Thesis-MUL/blob/main/notebooks/diversity.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ccq4t89VkPUr"
      },
      "source": [
        "##### Licensed under the Apache License, Version 2.0 (the \"License\");"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "iiydswCykMPJ"
      },
      "outputs": [],
      "source": [
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WFxVJ9GEkZP7"
      },
      "source": [
        "# The Diversity Objective\n",
        "\n",
        "This notebook demonstrates the diversity objective, which is used to generate multiple different visualizations from a single neuron or channel.\n",
        "\n",
        "# Feature visualization w/ Diversity function:\n",
        "  - it defines an img parametrization function\n",
        "  - constructs an optimization objective by maximizing a specific channel in the \"mixed5a\" layer and by introducing a diversity loss to encourage variarion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uUMzEXJJkx3H"
      },
      "source": [
        "## Install, Import, Load Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CaCvxcW3kYnd",
        "outputId": "27878187-df6f-4e82-f40b-fec7be687a7c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m82.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m61.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m45.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[32m565.7/664.8 MB\u001b[0m \u001b[31m143.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install --quiet git+https://github.com/greentfrapp/lucent.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MnjhvDrFkz6Y"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "from lucent.optvis import render, param, transform, objectives\n",
        "from lucent.modelzoo import inceptionv1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9MzZDxhGk3c1"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = inceptionv1(pretrained=True)\n",
        "_ = model.to(device).eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Ut62Mcwk8GU"
      },
      "source": [
        "## An Example\n",
        "\n",
        "With the diversity objective, we have to submit a batch of images for optimization. The diversity objective then tries to maximize the difference in feature representations between the images in the batch.\n",
        "\n",
        "Specifically, the objective penalizes cosine similarity between the feature representations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ac83ed7bk9yC"
      },
      "outputs": [],
      "source": [
        "batch_param_f = lambda: param.image(128, batch=4) #created 4 images of size 128x128\n",
        "\n",
        "obj = objectives.channel(\"mixed5a\", 9) - 1e2 * objectives.diversity(\"mixed5a\")\n",
        "\n",
        "_ = render.render_vis(model, obj, batch_param_f, show_inline=True)\n",
        "#! this is where the input img is gradually modified to make the selected neuron fire more"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# above:\n",
        "This is an exampke in which we maximize activation of channel 9 in layer mixed5a, add a diversity term and the coefficient 100 balances activation strength vs. diversity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D5ph2YLbm_wy"
      },
      "source": [
        "## More Examples\n",
        "\n",
        "More examples reproducing results from the Distill article [Feature Visualization](https://distill.pub/2017/feature-visualization/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Below, an exmaple with more diversity:\n",
        "Here the difference is that it targets channel 97 in mixed4a. instead and uses a higher diversity weight (1000), leading to even more varied outputs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WO2rOb0ynKKc"
      },
      "outputs": [],
      "source": [
        "# Different curvy facets\n",
        "\n",
        "obj = objectives.channel(\"mixed4a\", 97) - 1e3 * objectives.diversity(\"mixed4a\") # here we use a higher weight on the diversity term\n",
        "\n",
        "_ = render.render_vis(model, obj, batch_param_f, show_inline=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IHjIBu6SnK69"
      },
      "outputs": [],
      "source": [
        "# Different shapes with the same fur texture\n",
        "\n",
        "obj = objectives.channel(\"mixed4a\", 143) - 1e2 * objectives.diversity(\"mixed4a\")\n",
        "\n",
        "_ = render.render_vis(model, obj, batch_param_f, show_inline=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZmmS4duOoU65"
      },
      "outputs": [],
      "source": [
        "# Cars and Cats\n",
        "\n",
        "obj = objectives.channel(\"mixed4e\", 55) - 1e2 * objectives.diversity(\"mixed4e\")\n",
        "\n",
        "_ = render.render_vis(model, obj, batch_param_f, show_inline=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fkPJUbR7qCW2"
      },
      "source": [
        "## Try it out!\n",
        "\n",
        "Select your favorite channel or neuron or just pick a random one! Try adjusting the weight on the diversity term to see how that makes a difference!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uSIaYrRdofil"
      },
      "outputs": [],
      "source": [
        "# Flowers and err... other stuff?\n",
        "\n",
        "batch_param_f = lambda: param.image(128, batch=4, decorrelate=False) # disable channel decorrelation for more trippy images\n",
        "\n",
        "obj = objectives.channel(\"mixed4d_3x3_bottleneck_pre_relu_conv\", 139) - 1e3 * objectives.diversity(\"mixed4d_3x3_bottleneck_pre_relu_conv\")\n",
        "\n",
        "_ = render.render_vis(model, obj, batch_param_f, show_inline=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## What is happening here?\n",
        "This notebook is visualizing what different neurons, or channels, in INCEPTIONV1 \"see\".\n",
        "\n",
        "# Define the objective: make the nw activate a specific neuron\n",
        "    obj = objectives.channel(\"mixed5a\", 9) - 1e2 * objectives.diversity(\"mixed5a\")\n",
        "        we want channel 9 to become as active as possible, thus this forces the nw to generate an image that storngly activates that specific neuron.\n",
        "        objectives.diversity() encourages varied images instead of identical ones. the -1e2* means diversity is weighted 100 times less than activation.\n",
        "    Without diversity, we'd get 4 almost identical images, with it instead the nw tries different ways to activate the same neuron, leading to more creative and diverse results.\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "include_colab_link": true,
      "name": "diversity.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
